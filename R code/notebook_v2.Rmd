---
title: "Osu Data Analysis and Visualizations"
output: html_notebook
---
## Introduction
The following data analysis is about the online (FTP) rhythm-based game called [Osu!](osu.ppy.sh). In Osu!, we click circles. We click them to the rhythm of a song (or 'beat-map'). That pretty much sums up the game itself. What's interesting is that players can be ranked based on their overall performance. The best players have a higher overall performance (abbreviated as 'pp'), and we can see their names appear on the [Performance Rankings](https://osu.ppy.sh/rankings/osu/performance). I went and took the liberty of gathering as much data as I can from this list. See the folder 'Python Code' for more about how I gathered the data. 

This notebook is what I've gathered from the data. Spoiler: It isn't much. But I have some cool visualizations. 

## Coding
We will mostly use packages from the tidyverse. 
```{r}
library(readr)
library(dplyr) # ignore the warning
library(tidyr)
library(ggplot2)

lables <- c("name","performance","accuracy","PC","SS","S","A","Date")

Player1 <- read_csv("../Python code/test2.csv",col_names = lables) %>%
  select(performance,PC,SS,S,A,Date) %>%
  filter(Date>as.Date("2016-01-01")) %>%    # useless data imo
  filter(!(between(Date,as.Date("2017-08-01"),as.Date("2017-12-31")))) %>% # just filtering dirty data
  mutate(group = 'old')

Player2 <- read_csv("../Python code/test3.csv",col_names = lables) %>%
  select(performance,PC,SS,S,A,Date) %>%
  mutate(group = 'new')

Player <- rbind(Player1,Player2)
```
I have two datasets here. One dataset uses the most current information on the Performane Rankings. The other dataset are from past Performance Rankings, before late 2017. There are a handful of differences between the two datasets, so we'll cover that along our analysis. The tibble `Player` will contain both `new` and `old` values.

There are a handful of outliers in the above datasets, so we are going to filter some values. This is hindsight of the column values having a skewed Gaussian (normal/bell-curve) distribution. 
```{r}
# helper function to help with repeated code
is_in_range <- function(obj) {
  between(obj,mean(obj)-4*sd(obj),mean(obj)+4*sd(obj))
}

filtered_data <- Player %>%
  filter(
    is_in_range(PC),
    is_in_range(S),
    is_in_range(A),
    is_in_range(SS)
  ) 

#useful for some plotting
filtered_data_means <-filtered_data %>%
  group_by(group) %>%
  summarise(mean_pf = mean(performance),
            mean_pc = mean(PC),
            mean_s = mean(S),
            mean_a = mean(A),
            mean_ss = mean(SS)) %>%
  mutate(
    group = ifelse(group == 'new','new mean','old mean')
  )

# mutating tibble filtered_data_means for the upcoming graph. For faceting purposes
filtered_data_means_2 <- filtered_data_means %>%
  gather(key = key, value = value, mean_s, mean_a) %>%
  mutate(key = ifelse(key == "mean_s","S","A")) 
```




Let's start out with some basic line-graphs and histograms. We'll comapre the difference between the 'old' and the 'new' datasets. 
```{r}
ggplot(Player) +
  geom_point(mapping = aes(x = Date, y = performance, color = group))

ggplot(Player) +
  geom_point(aes(1:nrow(Player),performance,color = Date))

Player %>%
  arrange(desc(performance)) %>%
  ggplot(mapping = aes(x = 1:nrow(Player), y = performance, color = group)) +
  geom_point()
```
We can clearly see how chopped up the data is in the first scatter plot. In particular, the `old` dataset is chopped up. A complete-ish dataset from the year, say, 2016 should look like the smooth line in the red. The chopped up look is based on what was made available to us with the [Wayback Machine](https://web.archive.org/web/*/osu.ppy.sh). 

We can see how the conjoined datasets form a wonky exponential decay curve. 
```{r}
#basic histogram. (Good). We have the mean lines included to see the differences in old and new data. 
ggplot(data = filtered_data) + 
  geom_histogram(mapping = aes(x= PC, fill = group), bins = 100) +
  geom_vline(data = filtered_data_means, mapping = aes(xintercept = mean_pc[1], color = 'new mean'), size = 1.25, linetype="twodash") +
  geom_vline(data = filtered_data_means, mapping = aes(xintercept = mean_pc[2], color = 'old mean'), size = 1.25, linetype="twodash") +
  scale_colour_manual('Lines',values = c("red","blue")) +
  theme_bw()
```
We see that the average `performance` has increased in time. The difference being `1367` in value.

```{r}
#(Very good) Faceted differences between past and new data (S and A comparisons only)
fac_histo <- filtered_data %>%
  gather(key = key, value = value, -performance, -PC, -Date, -group, -SS) %>%
  ggplot() +
  geom_histogram(mapping = aes(x = value, fill = group), bins = 100) +
  geom_vline(data = filtered_data_means_2, mapping = aes(xintercept = value, color = group), size = 1.25, linetype="twodash") +
  scale_colour_manual('Lines',values = c("red","blue")) +
  theme_bw()

fac_histo + facet_grid(key ~ .)
```
This second figures is a little interesting. It seems that current players have more `A` ranked maps on average nowadays. However, past players held more `S` ranked maps than current players on average. There's also an interesting question about the ratio of `SS/S/A' ranked maps in proportion to `play_count` and `performance`. See the Discussion section.

Now, let's look at some heat maps. 
```{r}
# (Okay enough for a plot). Interesting because faceted heat maps. 
ggplot(filtered_data) +
  geom_bin2d(aes(PC,performance)) +
  scale_fill_gradient2(high = "darkblue") +
#  facet_grid(. ~ group) +  # faceting doesn't look good though
  theme_bw()
```


```{r}
# (Questionable). I think we already pointed out how S/A differs. 
filtered_data %>%
  gather(key = key, value = value, S, A) %>%
  ggplot() +
  geom_bin2d(aes(value,PC)) +
  scale_fill_gradient2(high = "darkblue") +
  facet_grid(. ~ key) +
  theme_bw()
```
Now we'll take a closer look at performance. One thing gives us some trouble though. I am making the assumption that performance inflates over time (linearly), so it wouldn't be ideal to compare performaces at separate years. 

Consider the graph below of the top 50 players at separate points in time. 

```{r}
top_labels <- c('name', 'performance','accuracy','PC','SS','S','A','Date')
topPlayer <- read_csv("../Python code/test.csv",col_names = FALSE) 
colnames(topPlayer) <- top_labels

sorted_top_player <- topPlayer %>%
  select(performance, PC,SS,S,A, Date) %>%
  arrange(Date) %>%
  mutate(
    id = 1:800
  )

ggplot(sorted_top_player) +
  geom_point(aes(Date,performance,color = Date)) +
  theme_bw()
```
Now let's look at `PC` (play_count) of the top 50 players over time. 
```{r}
ggplot(sorted_top_player) +
  geom_point(aes(Date,PC,color = Date)) + 
  theme_bw()
```
And a quick overview of the distribution of `SS`/`S`/`A` over time
```{r}
sorted_top_player %>%
  gather(key=key,value=value,SS,S,A) %>%
  ggplot() +
    geom_point(aes(Date,value, color = Date)) +
    facet_grid(. ~ key) +
    theme_bw()
```
Okay, there are a handful of outliers, but there is no linear growth in `PC` (play count) or `SS`/`S`/`A` like we do with performance. This argument could be stronger if we had say top 500 data at separate points in time. This is a limitation of the WayBack Machine having enough archived urls. 

Let's make a linear model of performance as a function of time. 
```{r}
model <- lm(performance ~ Date,sorted_top_player)
c <- model$coefficients[2]
d <- model$coefficients[1]

# (VERY GOOD)
sorted_top_player %>%
  mutate(
    lm_performance = as.numeric(Date)*c + d
  ) %>%
  ggplot() +
  geom_point(aes(Date,performance)) + 
  geom_line(aes(Date,lm_performance, color = "linear model"), size = 2) +
  scale_color_manual(name = c("Line"), values = c("red")) +
  theme_bw()
```
This is a rough linear model, but it gives us some idea how performance 'inflates' over time. 

We can now give a type of correctional term to the 'old' player data, but we'll breifly study how performance can be modeled as a function of rank. First, let's partition the data into categories. 
```{r}
oldest_data <- filtered_data %>%
  filter(between(Date,as.Date("2016-01-01"),as.Date("2017-01-01"))) %>%
  arrange(desc(performance)) %>%
  mutate(
    id = 1:n()
  )

older_data <- filtered_data %>%
  filter(between(Date,as.Date("2017-01-01"),as.Date("2018-01-01"))) %>%
  arrange(desc(performance)) %>%
  mutate(
    id = 1:n()
  )
  
current_data <- filtered_data %>%
  filter(between(Date,as.Date("2019-01-01"),as.Date("2020-01-01"))) %>%
  arrange(desc(performance)) %>%
  mutate(
    id = 1:n()
  )
```

Now for some quick modeling. Note, after some observation, the log of performance can be modeled as the log of one over the Date. `log(performance) ~ log(1/(id+1))`

- This discovery was based on a simple obervation: It looked like performance could be modeled as an exponential decay term. After I took the log of performance, I expected to see a linear term since `log(exp(-x)) == -x`. This is not what i found. The `log(performance)` looked like it was exponentially decaying still. Even `log(log(performance))` still had a exponential decay look to it. I later realized that taking the log of `1/x` had an exponential decay look to it. So I used `log(performance) ~ log(1/x)`. This logs at this point are only for reducing the size of the values (keeping things less than 10).
```{r}
temp_model <- lm(log(performance) ~ log(1/(id+1)) , oldest_data)
temp_model$coefficients
a <- temp_model$coefficients[2] # coefficient
b <- temp_model$coefficients['(Intercept)']

temp_model_2 <- lm(log(performance) ~ log(1/(id+1)) , older_data)
temp_model_2$coefficients
a_2 <- temp_model_2$coefficients[2] # coefficient
b_2 <- temp_model_2$coefficients['(Intercept)']

temp_model_3 <- lm(log(performance) ~ log(1/(id+1)) , current_data)
temp_model_3$coefficients
a_3 <- temp_model_3$coefficients[2] # coefficient
b_3 <- temp_model_3coefficients['(Intercept)']
```
The differences in the intercepts will matter a lot here.

sd
```{r}
oldest_data %>%
  mutate(
    lm_performance = exp(a*log(1/(id+1)) + b)
  ) %>%
  ggplot() +
  geom_line(aes(id,performance, color = "Actual"), size = 1.5) +
  geom_line(aes(id,lm_performance, color = "Model"), size = 1.5) +
  scale_color_manual(name = c("Lines"), values = c("blue", "red")) +
  theme_bw()

older_data %>%
  mutate(
    lm_performance = exp(a_2*log(1/(id+2)) + b_2) # just shifting a bit so it can start the same
  ) %>%
  ggplot() +
  geom_line(aes(id,performance, color = "Actual"), size = 1.5) +
  geom_line(aes(id,lm_performance, color = "Model"), size = 1.5) +
  scale_color_manual(name = c("Lines"), values = c("blue", "red")) +
  theme_bw()

current_data %>%
  mutate(
    lm_performance = exp(a_3*log(1/(id+20)) + b_3) # just shifting a bit so it can start the same
  ) %>%
  ggplot() +
  geom_line(aes(id,performance, color = "Actual"), size = 1.5) +
  geom_line(aes(id,lm_performance, color = "Model"), size = 1.5) +
  scale_color_manual(name = c("Lines"), values = c("blue", "red")) +
  theme_bw()
```
Notice how that the curvs are not alike. The older data is a bit smoother as it dips down, and the current data has a steep drop before it mellows out. A summary of the models:

```{r}
summary_of_models <- tibble(
  id = 1:5000,
  lm_performance_current = exp(a_3*log(1/(id+20)) + b_3),
  lm_performance_older = exp(a_2*log(1/(id+2))+b_2),
  lm_performance_oldest = exp(a*log(1/(id+1))+b)
) 
summary_of_models %>%
  gather(key = key, value = value, -id) %>%
  ggplot() +
  geom_line(aes(id, value, color = key), size = 1.5) +
  theme_bw()
```
So the start will  be different, but the coefficient terms seem to matter the most. So we'll take the average of `a_2` and `a_3`. 

With this general model at our disposal, all we need is the starting value, `performance(ip = 0)`, to have a rough model 
